---
layout: post
title: We are looking for a new PhD student in AI Interpretability
date: 2015-11-07 16:11:00-0400
inline: false
related_posts: false
---

We are seeking a highly motivated and skilled research assistant to join our Research Team at IOL Lab at Zuse Institute Berlin. The successful candidate will work closely with our team on cutting-edge research projects in the field of numerical optimisation and Explainable Machine Learning.

***
The position is part of the MATH+ project ["Expanding Merlin-Arthur Classifiers - Interpretable Neural Networks through Interactive Proof Systems"](https://mathplus.de/research-2/emerging-fields/ef1-extracting-dynamical-laws-from-complex-data/ef1-24/). This research project is part of the Emerging Fields Area "Extracting dynamical Laws from Complex Data". Our work focuses on the mathematical analysis of interpretability in AI systems. We want to investigate under which conditions interacting agents have to communicate honestly about their reasoning process. Our aim is to develop a theoretically sound foundation to make modern AI systems safe for deployment in sensitive ares. MATH+, the Berlin Mathematics Research Center, is a cross-institutional and interdisciplinary Cluster of Excellence. It sets out to explore and further develop new approaches in application-oriented mathematics. For more information see: <https://mathplus.de>.

***
#### **Requirements:**
1. completed university degree (Diplom, Master or equivalent) in Mathematics, Computer Science or a closely related course of studies,
2. solid knowledge of probability theory
3. good programming skills (Python)
4. knowledge in computational complexity theory, graph theory and game theory are an advantage
5. fluent in English
6. independent thinker

Write me **(waeldchen@zib.de)** for further information. If you know a candidate that might be a good fit for this position, please forward them this document.
