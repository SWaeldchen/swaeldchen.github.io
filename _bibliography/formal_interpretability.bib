---
---

@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature machine intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{lapuschkin2016analyzing,
  title={Analyzing classifiers: Fisher vectors and deep neural networks},
  author={Lapuschkin, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Muller, Klaus-Robert and Samek, Wojciech},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2912--2920},
  year={2016}
}
@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{slack2020fooling,
  title={Fooling lime and shap: Adversarial attacks on post hoc explanation methods},
  author={Slack, Dylan and Hilgard, Sophie and Jia, Emily and Singh, Sameer and Lakkaraju, Himabindu},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  pages={180--186},
  year={2020}
}
@article{dimanov2020you,
  title={You shouldnâ€™t trust me: Learning models which conceal unfairness from multiple explanation methods.},
  author={Dimanov, Botty and Bhatt, Umang and Jamnik, Mateja and Weller, Adrian},
  year={2020},
  publisher={IOS Press}
}
@article{heo2019fooling,
  title={Fooling neural network interpretations via adversarial model manipulation},
  author={Heo, Juyeon and Joo, Sunghwan and Moon, Taesup},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}
@inproceedings{anders2020fairwashing,
  title={Fairwashing explanations with off-manifold detergent},
  author={Anders, Christopher and Pasliev, Plamen and Dombrowski, Ann-Kathrin and M{\"u}ller, Klaus-Robert and Kessel, Pan},
  booktitle={International Conference on Machine Learning},
  pages={314--323},
  year={2020},
  organization={PMLR}
}
@inproceedings{fong2017interpretable,
  title={Interpretable explanations of black boxes by meaningful perturbation},
  author={Fong, Ruth C and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={3429--3437},
  year={2017}
}
@article{macdonald2019rate,
  title={A rate-distortion framework for explaining neural network decisions},
  author={MacDonald, Jan and W{\"a}ldchen, Stephan and Hauch, Sascha and Kutyniok, Gitta},
  journal={arXiv preprint arXiv:1905.11092},
  year={2019}
}
@article{ribeiro2016model,
  title={Model-agnostic interpretability of machine learning},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  journal={arXiv preprint arXiv:1606.05386},
  year={2016}
}
@article{macdonald2021interpretable,
  title={Interpretable neural networks with frank-wolfe: Sparse relevance maps and relevance orderings},
  author={Macdonald, Jan and Besan{\c{c}}on, Mathieu and Pokutta, Sebastian},
  journal={arXiv preprint arXiv:2110.08105},
  year={2021}
}
